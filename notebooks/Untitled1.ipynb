{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af0456d-8492-433b-a782-9b47cf5884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8940de25-ca54-4cc7-b87a-7633d259fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import count\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sigmaclast_data import SigmaclastFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cf7511f-6487-4428-9813-e336df59c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"../data/original_data/\")\n",
    "\n",
    "# transform = T.Compose([T.ToTensor(), T.Resize((32, 32))])\n",
    "transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e919fb-75fd-4de9-bed6-72a0c96284c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SigmaclastFolder(root, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cd3ae35-d979-400b-848f-794492ed2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f8965cd-0e92-44ab-895a-da55ffb492d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSigmaclastFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mdefault_loader\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x168eb7dc0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A generic data loader where the images are arranged in this way by default: ::\n",
       "\n",
       "    root/dog/xxx.png\n",
       "    root/dog/xxy.png\n",
       "    root/dog/[...]/xxz.png\n",
       "\n",
       "    root/cat/123.png\n",
       "    root/cat/nsdf3.png\n",
       "    root/cat/[...]/asd932_.png\n",
       "\n",
       "This class inherits from :class:`~torchvision.datasets.DatasetFolder` so\n",
       "the same methods can be overridden to customize the dataset.\n",
       "\n",
       "Args:\n",
       "    root (string): Root directory path.\n",
       "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
       "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
       "    target_transform (callable, optional): A function/transform that takes in the\n",
       "        target and transforms it.\n",
       "    loader (callable, optional): A function to load an image given its path.\n",
       "    is_valid_file (callable, optional): A function that takes path of an Image file\n",
       "        and check if the file is a valid file (used to check of corrupt files)\n",
       "\n",
       " Attributes:\n",
       "    classes (list): List of the class names sorted alphabetically.\n",
       "    class_to_idx (dict): Dict with items (class_name, class_index).\n",
       "    imgs (list): List of (image path, class_index) tuples\n",
       "\u001b[0;31mFile:\u001b[0m           ~/projects/microstructures/code/sigmaclast_data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SigmaclastFolder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89f9b0a9-19c0-4b86-98b0-ce6c73b73707",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr = count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8195cb38-89a4-457e-a8f1-3818b76a9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('..', 'data', 'original_data')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8fade643-531c-4511-90f2-3e075cbe10d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a961aac-1e91-4d38-a1f6-ccdfabd2221d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "99dda58c-67e0-41e2-83f6-7738234711f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(root):\n",
    "    root = Path(root)\n",
    "    original_dir = root/\"original_data\"\n",
    "    CW_dir = root/\"processed_data/CW\"\n",
    "    CCW_dir = root/\"processed_data/CCW\"\n",
    "    CW_dir.mkdir(parents=True, exist_ok=True)\n",
    "    CCW_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    img_count = count()\n",
    "    \n",
    "    def preprocess_img(img_file, label):\n",
    "        img = cv2.imread(str(img_file), cv2.IMREAD_COLOR)\n",
    "        # `1` flips img horizonally.\n",
    "        # This flips the label as well.\n",
    "        # TODO: add explanation why...\n",
    "        img_flipped = cv2.flip(img, 1)\n",
    "        img_num = next(img_count)\n",
    "        name = f\"img_{img_num}_{label}.jpg\"\n",
    "        name_flipped = f\"img_{img_num}_{label}.jpg\"\n",
    "        \n",
    "        try:\n",
    "            if label == \"CW\":\n",
    "                cv2.imwrite(str(CW_dir/name), img)\n",
    "                cv2.imwrite(str(CCW_dir/name_flipped), img_flipped)\n",
    "            else:\n",
    "                cv2.imwrite(str(CCW_dir/name), img)\n",
    "                cv2.imwrite(str(CW_dir/name_flipped), img_flipped)\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(f\"Continuing...\")\n",
    "            \n",
    "\n",
    "    for directory in original_dir.iterdir():\n",
    "        label = directory.parts[-1]\n",
    "        if label == \"CW\" or label == \"CCW\":\n",
    "            for img_file in directory.iterdir():\n",
    "                preprocess_img(img_file, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "baa6faca-87cb-49e7-a41d-fa6a0bcb190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: OpenCV(4.5.5) /Users/runner/miniforge3/conda-bld/libopencv_1648505774709/work/modules/imgcodecs/src/loadsave.cpp:801: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
      "\n",
      "Continuing...\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset(\"../data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstructures",
   "language": "python",
   "name": "microstructures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
